# PathRecall: Retrieval-Augmented Visual Question Answering for Indoor Navigation

## ğŸ“ Overview
**PathRecall** is a research and engineering prototype that explores how *retrieval-augmented temporal memory* can enhance **Visual Question Answering (VQA)** in **indoor navigation** scenarios.  
Unlike conventional VQA models that operate on a single image, PathRecall maintains an evolving memory of previously encountered frames.  
This enables answering context-dependent queries such as:  
> *â€œEarlier, when I passed by the recycling area with the number 3 sign, what kind of seating did I encounter?â€*

The system integrates a custom **MemoryNet retriever**, a modified **BLIP-2 backbone**, and a **RAG-style pipeline**, showing how temporal memory retrieval improves accessibility of built environments for **visually impaired (VI)** users.

---

## ğŸ”‘ Key Features
- **Temporal Memory Retrieval**: Maintains an index of past video frames for history-aware QA.  
- **MemoryNet**: A lightweight retriever trained with MiniLM embeddings + BLIP-2 features.  
- **Question-Aware Captioning**: Generates scene descriptions conditioned on the query.  
- **RAG Pipeline**: Connects retrieval with answer generation to ensure grounded responses.  
- **Assistive Focus**: Designed with applications in accessibility and indoor navigation in mind.  

---

## ğŸ“‚ Project Structure
Pathrecall/                 # è¿™æ˜¯ä½ çš„é¡¹ç›®æ ¹ç›®å½•
â”œâ”€â”€ src/                    # "source"ï¼Œæºç æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ memorynet/          # å­˜æ”¾ MemoryNet çš„ä»£ç ï¼ˆè®­ç»ƒ & æ¨ç†ï¼‰
â”‚   â”œâ”€â”€ blip2_mod/          # å­˜æ”¾ä½ ä¿®æ”¹è¿‡çš„ BLIP-2 æ¨¡å—
â”‚   â”œâ”€â”€ rag_pipeline/       # å­˜æ”¾ RAGï¼ˆæ£€ç´¢+ç”Ÿæˆï¼‰çš„ä»£ç 
â”‚
â”œâ”€â”€ data/                   # æ•°æ®ç›®å½•ï¼ˆå¤ªå¤§ï¼Œä¸ä¸Šä¼  GitHubï¼‰
â”‚   â”œâ”€â”€ features/           # å­˜ BLIP-2 æå–çš„ç‰¹å¾ï¼ˆ.npyç­‰ï¼‰
â”‚   â”œâ”€â”€ memoryrank.jsonl    # MemoryNet è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ ...                 
â”‚
â”œâ”€â”€ notebooks/              # å­˜æ”¾ Jupyter Notebookï¼Œç”¨æ¥åšå®éªŒ & å¯è§†åŒ–
â”‚   â”œâ”€â”€ train_memorynet.ipynb
â”‚   â”œâ”€â”€ evaluation.ipynb
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/                # å­˜æ”¾ç»“æœï¼Œæ¯”å¦‚æ¨¡å‹è¾“å‡ºã€å›¾è¡¨ã€è®ºæ–‡é‡Œç”¨çš„å›¾
â”‚   â”œâ”€â”€ figures/            # ç»˜å›¾ï¼ˆç²¾åº¦æ›²çº¿ã€ç¤ºæ„å›¾ç­‰ï¼‰
â”‚   â”œâ”€â”€ samples/            # ç¤ºä¾‹ç»“æœï¼ˆè¾“å…¥é—®é¢˜ + æ£€ç´¢å¸§ + è¾“å‡ºç­”æ¡ˆï¼‰
â”‚   â””â”€â”€ evaluation.md       # å®éªŒæŠ¥å‘Šï¼ˆè¯¦ç»†çš„è¯„ä»·æŒ‡æ ‡ï¼‰
â”‚
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£


---

## âš™ï¸ Installation
```bash
git clone https://github.com/pdu3/pathrecall.git
cd pathrecall
conda create -n pathrecall python=3.10
conda activate pathrecall
pip install -r requirements.txt

## ğŸ–¼ï¸ Example Usage
from pathrecall import MemoryNet, RAGPipeline

retriever = MemoryNet.load_pretrained("checkpoints/memorynet.pt")
pipeline = RAGPipeline(retriever=retriever)

question = "When I looked up at the green exit sign, which direction should I have gone?"
answer, frames = pipeline.answer(question)

print("Answer:", answer)

